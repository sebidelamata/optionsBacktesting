---
output: html_document
title: 'Gamma Gamma Hey 
(an options analysis) Part One/: Primary Data Collection and Cleaning'
layout: post
---

# Gamma Gamma Hey 

## (an options analysis) 

# Part One: Primary Data Collection and Cleaning




## Abstract

In this first post in a series analyzing real-world derivatives data, we set up a Raspberry Pi 4 with a R Shiny Server. R and shell scripts are used to create a table within the PostgreSQL database to hold the options data. Additional scripts and a cronjob are used to automate scraping data from the CBOE open access API and appending the data to the table in the PostgreSQL database. An R markdown is used to take an initial look at our data. 

## Background

## Computing Environment

#### Hardware

```{r}


system(
  "cat /sys/firmware/devicetree/base/model",
  intern = TRUE
)
```

#### R Environment

```{r}

version[c(2,13)]

installed.packages()[,3]

```

## Scraping options data from the CBOE

```{r}
# import our libraries
library(dplyr)
library(jsonlite)
library(stringi)

```

```{r}

# let's pick a ticker to scrape
ticker <- "QQQ"

# create our scraping address
scrape_target <- paste0(
  "https://cdn.cboe.com/api/global/delayed_quotes/options/",
  ticker,
  ".json"
  )
  
print(scrape_target)

```

```{r}
# next we read the json data at our scrape target
scrape_data <- read_json(
    scrape_target,
    simplifyVector = TRUE
  )

```


```{r}

typeof(scrape_data)

```


```{r}

glimpse(scrape_data$data$options)

```

```{r}

# make it into a data frame
option_data <- as.data.frame(
  scrape_data$data$options
)

  # clean last trade datetime from string
  option_data$last_trade_time <- as.POSIXct(
    option_data$last_trade_time, 
    "%Y-%m-%dT%H:%M:%S", 
    tz = "America/Chicago"
    )
  
  # grab umderlying close
  option_data$underlying_close <- scrape_data$data$close
```
  
```{r}

print(option_data$option[1])

```
  
```{r}
  # grab our strike price from the option name string
  option_data$strike_price <- as.numeric(stri_sub(option_data$option, -8)) / 1000
   
  # grab our contract type from the option name string
  option_data$contract_type <- as.factor(stri_sub(option_data$option, -9, -9))
  
  # grab our underlying ticker from the option name string
  option_data$underlying_ticker <- as.factor(stri_sub(option_data$option, -999, -16))
  
  # grab our underlying ticker from the option name string
  option_data$expiration_date <- as.Date(
    stri_sub(option_data$option, -15, -10),
    format = "%y%m%d"
    )
```

```{r}

  # if we want to set this up to scrape every day
  # we need to create a column to record 
  # on what day the data was scraped
  option_data$scrape_date <- Sys.Date()
  
  # since we have already taken all the useful data
  # from the option column, we can keep using it as
  # a unique identifier for our table if we append
  # the scrape date to the end of the string
  option_data$option <- paste0(
    option_data$option,
    as.character(Sys.Date())
  )

```