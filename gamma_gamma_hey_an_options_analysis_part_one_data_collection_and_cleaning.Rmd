---
output: html_document
title: 'Gamma Gamma Hey 
(an options analysis) Part One/: Primary Data Collection and Cleaning'
layout: post
---

# Gamma Gamma Hey 

## (an options analysis) 

# Part One: Primary Data Collection and Cleaning




## Abstract

In this first post in a series analyzing real-world derivatives data, we set up a Raspberry Pi 4 with a R Shiny Server. R and shell scripts are used to create a table within the PostgreSQL database to hold the options data. Additional scripts and a cronjob are used to automate scraping data from the CBOE open access API and appending the data to the table in the PostgreSQL database. An R markdown is used to take an initial look at our data. 

## Background

## Computing Environment

#### Hardware

```{r}


system(
  "cat /sys/firmware/devicetree/base/model",
  intern = TRUE
)
```

#### R Environment

```{r}

version[c(2,13)]

installed.packages()[,3]

```

## Scraping options data from the CBOE

### Scraping a single ticker (scraper.R)

```{r}
# import our libraries
library(dplyr)
library(jsonlite)
library(stringi)

```

```{r}

# let's pick a ticker to scrape
ticker <- "QQQ"

# create our scraping address
scrape_target <- paste0(
  "https://cdn.cboe.com/api/global/delayed_quotes/options/",
  ticker,
  ".json"
  )
  
print(scrape_target)

```

```{r}
# next we read the json data at our scrape target
scrape_data <- read_json(
    scrape_target,
    simplifyVector = TRUE
  )

```


```{r}

typeof(scrape_data)

```


```{r}

glimpse(scrape_data$data$options)

```

```{r}

# make it into a data frame
option_data <- as.data.frame(
  scrape_data$data$options
)

  # clean last trade datetime from string
  option_data$last_trade_time <- as.POSIXct(
    option_data$last_trade_time, 
    "%Y-%m-%dT%H:%M:%S", 
    tz = "America/Chicago"
    )
  
  # grab umderlying close
  option_data$underlying_close <- scrape_data$data$close
```
  
```{r}

print(option_data$option[1])

```
  
```{r}
  # grab our strike price from the option name string
  option_data$strike_price <- as.numeric(stri_sub(option_data$option, -8)) / 1000
   
  # grab our contract type from the option name string
  option_data$contract_type <- as.factor(stri_sub(option_data$option, -9, -9))
  
  # grab our underlying ticker from the option name string
  option_data$underlying_ticker <- as.factor(stri_sub(option_data$option, -999, -16))
  
  # grab our underlying ticker from the option name string
  option_data$expiration_date <- as.Date(
    stri_sub(option_data$option, -15, -10),
    format = "%y%m%d"
    )
```

```{r}

  # if we want to set this up to scrape every day
  # we need to create a column to record 
  # on what day the data was scraped
  option_data$scrape_date <- Sys.Date()
  
  # since we have already taken all the useful data
  # from the option column, we can keep using it as
  # a unique identifier for our table if we append
  # the scrape date to the end of the string
  option_data$option <- paste0(
    option_data$option,
    as.character(Sys.Date())
  )
  
print(option_data[1,])

```

### Iterating our scraper over our watchlist (grab_watchlist.R)

```{r}

# grab our scraper script
source("/home/sebi/optionsBacktesting/scraper.R")

```

```{r}


  # declare the tickers we want in our watchlist
watchlist <- c(
  "QQQ",
  "SPY",
  "IWM",
  "SLYV",
  "FXI",
  "DIA",
  "ARKK",
  "FEZ",
  "EEM",
  "EWW",
  "EWZ",
  "XLB",
  "XLV",
  "XLU",
  "XLF",
  "XLI",
  "XOP",
  "GLD",
  "SLV",
  "TLT",
  "HYG"
)

print(watchlist)

```
  
```{r}
  # create an empty dataframe 
  watchlist_data <- data.frame()

  summary(watchlist_data)
  
```

```{r}
  # for each ticker in the watchlist grab the option data
  # and union it to the watchlist_data df
  watchlist_data <- do.call(
    rbind,
    lapply(
      watchlist,
      grab_option_data
      )
    )

print(unique(as.factor(watchlist_data$underlying_ticker)))
```

```{r}
# number of rows for a single day's pull
nrow(watchlist_data)

```

### Creating a table in PostgreSQL (create_watchlist_table.R)

```{r}

library(RPostgreSQL)

source("/home/sebi/optionsBacktesting/grab_watchlist.R")
```

```{r eval=FALSE}

# set driver name
driver_name <- dbDriver(drvName = "PostgreSQL")
  
# establish database connection
db <- DBI::dbConnect(driver_name,
		     dbname="sebi",
		     host="localhost",
		     port = 5432
		     )
```

```{r eval=FALSE}

# grab todays watchlist data
watchlist_data <- grab_watchlist()

```  
  
```{r eval=FALSE}

# create our table with todays data (overwrite if already exists)
DBI::dbWriteTable(
  db,
  value =  watchlist_data,
  name = "watchlist_data",
  overwrite = TRUE,
  row.names = FALSE
)
```


```{r eval=FALSE}  
# set primary key column
DBI::dbSendQuery(
    db,
    'ALTER TABLE watchlist_data ADD PRIMARY KEY ("option")'
    )
```

```{r eval=FALSE}
  # disconnect from database
  DBI::dbDisconnect(db)

```

### Appending to the existing PostgreSQL table (append_watchlist_data.R)

```{r eval=FALSE}

library(DBI)
library(RPostgreSQL)

source("/home/sebi/optionsBacktesting/grab_watchlist.R")


append_watchlist_data <- function(){
  
  # grab our watchlist data
  watchlist_data <- grab_watchlist()
  
  # establish driver name
  driver_name <- dbDriver(drvName = "PostgreSQL")
  
  # create database connection
  db <- DBI::dbConnect(driver_name,
                       dbname="sebi",
                       host="localhost",
                       port = 5432
  )
  
  # append our scraped data to the table
  DBI::dbWriteTable(
    db,
    name = "watchlist_data",
    value = watchlist_data,
    row.names = FALSE,
    append = TRUE
  )
  
  # close database connection
  DBI::dbDisconnect(db)
}

```

### Only scrape for data on market days (trading_day_scheduler.R)

```{r}

library(timeDate)

source("/home/sebi/optionsBacktesting/append_watchlist_data.R")

if(as.POSIXlt(Sys.Date())$wday %in% 1:5 & !(Sys.Date() %in% as.Date(timeDate::holidayNYSE()))){
  append_watchlist_data()
} else {
  message("Market Closed Today")
}

```

```{r}

# set driver name
driver_name <- dbDriver(drvName = "PostgreSQL")

# establish database connection
db <- DBI::dbConnect(driver_name,
                     dbname = "sebi",
                     host = "192.168.0.12",
                     port = 5432
)

res <- dbSendQuery(db, "SELECT * FROM watchlist_data;")
data_pull <- dbFetch(res)
dbClearResult(res)
dbDisconnect(db)

```
