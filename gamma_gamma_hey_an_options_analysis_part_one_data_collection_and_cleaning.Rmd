---
output: html_document
title: 'Gamma Gamma Hey 
(an options analysis) Part One/: Primary Data Collection and Cleaning'
layout: post
---

# Gamma Gamma Hey 

## (an options analysis) 

# Part One: Primary Data Collection and Cleaning




## Abstract

In this first post in a series analyzing real-world derivatives data, we set up a Raspberry Pi 4 with a R Shiny Server. R and shell scripts are used to create a table within the PostgreSQL database to hold the options data. Additional scripts and a cronjob are used to automate scraping data from the CBOE open access API and appending the data to the table in the PostgreSQL database. An R markdown is used to take an initial look at our data. 

## Background

## Computing Environment

#### Hardware

```{r}


system(
  "cat /sys/firmware/devicetree/base/model",
  intern = TRUE
)
```

#### R Environment

```{r}

version[c(2,13)]

installed.packages()[,3]

```

## Scraping options data from the CBOE

```{r}
# import our libraries
library(dplyr)
library(jsonlite)
library(stringi)

```

```{r}

# let's pick a ticker to scrape
ticker <- "QQQ"

# create our scraping address
scrape_target <- paste0(
  "https://cdn.cboe.com/api/global/delayed_quotes/options/",
  ticker,
  ".json"
  )
  
print(scrape_target)

```

```{r}
# next we read the json data at our scrape target
scrape_data <- read_json(
    scrape_target,
    simplifyVector = TRUE
  )

```


```{r}

typeof(scrape_data)

```

```{r}

summary(scrape_data$data$options)

```

```{r}

glimpse(scrape_data$data$options)

```